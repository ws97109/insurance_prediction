---
name: 資料準備與特徵工程
status: open
created: 2025-10-09T02:52:41Z
updated: 2025-10-09T02:52:41Z
github: [Will be updated when synced to GitHub]
depends_on: []
parallel: false
conflicts_with: []
---

# Task: 資料準備與特徵工程

## Description

載入 UCI COIL 2000 保險資料集，執行探索性資料分析 (EDA)、資料清洗、特徵工程，並將資料分割為訓練集與測試集。這是整個專案的基礎，產出的清洗資料將供後續模型訓練使用。

**資料來源**:
- `ticdata2000.txt` - 訓練資料 (5822 筆)
- `ticeval2000.txt` - 測試資料 (4000 筆)
- `tictgts2000.txt` - 目標變數
- `TicDataDescr.txt` - 資料描述
- `dictionary.txt` - 資料字典

## Acceptance Criteria

- [ ] 成功載入所有 COIL 2000 資料檔案 (訓練集 5822 筆 + 測試集 4000 筆)
- [ ] 完成 EDA 分析，產出 Jupyter Notebook 報告，包含：
  - 資料分布視覺化 (直方圖、箱型圖)
  - 缺失值統計與分析
  - 特徵相關性矩陣 (correlation matrix)
  - 類別不平衡分析 (目標變數分布)
- [ ] 資料清洗完成：
  - 處理缺失值 (填補或移除)
  - 處理異常值 (outlier detection)
  - 資料標準化 (StandardScaler / MinMaxScaler)
- [ ] 特徵工程完成：
  - 編碼類別變數 (Label Encoding / One-Hot Encoding)
  - 產生衍生特徵 (如產品多樣性、總保費估算)
  - 特徵選擇 (移除低變異或高度相關特徵)
- [ ] 資料分割：訓練集 / 驗證集 / 測試集 (例如: 70% / 15% / 15%)
- [ ] 產出清洗後的資料檔案：
  - `train_cleaned.csv` - 清洗後的訓練資料
  - `val_cleaned.csv` - 驗證資料
  - `test_cleaned.csv` - 清洗後的測試資料
  - `feature_dict.json` - 特徵字典 (欄位名稱、類型、說明)

## Technical Details

### 實作方式
使用 **Jupyter Notebook** + **pandas** + **scikit-learn** 進行資料處理。

### 關鍵步驟

#### 1. 資料載入
```python
import pandas as pd
import numpy as np

# 載入資料 (假設為 tab-separated 格式)
train_data = pd.read_csv('ticdata2000.txt', sep='\t', header=None)
test_data = pd.read_csv('ticeval2000.txt', sep='\t', header=None)
targets = pd.read_csv('tictgts2000.txt', sep='\t', header=None)

# 合併目標變數
train_data['target'] = targets.values
```

#### 2. EDA 分析
- 使用 `df.info()`, `df.describe()` 檢查基本統計
- 使用 `matplotlib` / `seaborn` 視覺化資料分布
- 使用 `df.isnull().sum()` 檢查缺失值
- 使用 `df.corr()` 計算相關性矩陣

#### 3. 資料清洗
```python
from sklearn.preprocessing import StandardScaler

# 處理缺失值 (策略: 中位數填補數值型、眾數填補類別型)
train_data.fillna(train_data.median(), inplace=True)

# 異常值處理 (例如: IQR 方法)
Q1 = train_data.quantile(0.25)
Q3 = train_data.quantile(0.75)
IQR = Q3 - Q1
train_data = train_data[~((train_data < (Q1 - 1.5 * IQR)) | (train_data > (Q3 + 1.5 * IQR))).any(axis=1)]

# 標準化
scaler = StandardScaler()
train_data[numeric_cols] = scaler.fit_transform(train_data[numeric_cols])
```

#### 4. 特徵工程
```python
# 衍生特徵: 計算客戶持有的保險產品總數
train_data['total_products'] = train_data[product_cols].sum(axis=1)

# 衍生特徵: 產品多樣性 (Shannon Entropy)
from scipy.stats import entropy
train_data['product_diversity'] = train_data[product_cols].apply(entropy, axis=1)
```

#### 5. 資料分割
```python
from sklearn.model_selection import train_test_split

# 分割訓練集與驗證集
X = train_data.drop('target', axis=1)
y = train_data['target']

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.15, random_state=42, stratify=y
)
```

### 檔案位置
- **Notebook**: `notebooks/01_data_preparation.ipynb`
- **清洗資料**: `data/processed/train_cleaned.csv`, `data/processed/val_cleaned.csv`, `data/processed/test_cleaned.csv`
- **特徵字典**: `data/processed/feature_dict.json`

### 風險與挑戰
1. **類別不平衡問題**: 僅約 6% 客戶購買旅行保險，需考慮使用 SMOTE 或調整類別權重
2. **缺失值過多**: 若某特徵缺失率 > 30%，考慮直接移除該特徵
3. **資料洩漏 (Data Leakage)**: 確保測試集完全獨立，不參與任何前處理步驟的參數計算 (如 scaler.fit)

## Dependencies

### 外部依賴
- [ ] UCI COIL 2000 資料集已下載至 `insurance+company+benchmark+coil+2000/` 目錄
- [ ] Python 環境已安裝相關套件：
  - pandas >= 1.3.0
  - numpy >= 1.21.0
  - scikit-learn >= 1.0.0
  - matplotlib >= 3.4.0
  - seaborn >= 0.11.0
  - scipy >= 1.7.0

### 內部依賴
- [ ] 無 (此為第一個任務，無前置依賴)

## Effort Estimate

- **規模**: M (中型)
- **預估時數**: 40 小時 (2 週，每天 4 小時)
  - EDA 分析: 12 小時
  - 資料清洗: 12 小時
  - 特徵工程: 12 小時
  - 文件撰寫: 4 小時
- **可並行**: false (此為基礎任務，必須優先完成)

## Definition of Done

- [x] Jupyter Notebook 完成並可重現執行
- [x] 清洗後的訓練/驗證/測試資料集已儲存為 CSV 檔案
- [x] 特徵字典已產出 (JSON 格式)
- [x] EDA 報告包含完整的視覺化圖表與統計摘要
- [x] 資料品質檢查通過：
  - 無缺失值 (或已妥善處理)
  - 無重複記錄
  - 數值範圍合理 (標準化後均值≈0, 標準差≈1)
- [x] Code Review 完成 (由 ML 工程師主管審查)
- [x] 資料檔案已提交至版本控制 (Git LFS 或 DVC)
