---
name: FastAPI 後端開發
status: open
created: 2025-10-09T02:52:41Z
updated: 2025-10-09T02:52:41Z
github: [Will be updated when synced to GitHub]
depends_on: [002]
parallel: false
conflicts_with: []
---

# Task: FastAPI 後端開發

## Description

使用 FastAPI 建構 RESTful API 服務，實作模型推論邏輯、資料庫操作、快取機制。提供單筆預測、批量預測、客戶分群等核心 API 端點，並整合已訓練好的 DQN/XGBoost 模型。

**核心功能**:
- 單筆客戶預測 (< 3 秒回應時間)
- 批量客戶預測 (非同步處理)
- 客戶價值分群
- 模型效能指標查詢
- API 認證 (JWT)
- Redis 快取整合

## Acceptance Criteria

### API 端點實作
- [ ] `POST /api/v1/predict/single` - 單筆客戶預測
  - 輸入: 客戶特徵 (86 維向量)
  - 輸出: Top 3 推薦產品 + 購買機率
  - 回應時間: < 3 秒 (95th percentile)
- [ ] `POST /api/v1/predict/batch` - 批量預測 (非同步)
  - 輸入: CSV 檔案 (最多 500 筆)
  - 輸出: Task ID
  - 處理時間: < 10 分鐘
- [ ] `GET /api/v1/predict/batch/{task_id}` - 查詢批量預測結果
- [ ] `POST /api/v1/segment` - 客戶分群
  - 輸入: 客戶特徵
  - 輸出: 分群標籤 (high/medium/low) + 評分 (0-100)
- [ ] `GET /api/v1/models/metrics` - 模型效能指標
  - 輸出: 準確率、精確率、召回率等

### 資料庫整合
- [ ] PostgreSQL ORM 模型定義完成 (SQLAlchemy)
  - `customers` 表
  - `predictions` 表
  - `segments` 表
- [ ] CRUD 操作實作完成
- [ ] 資料庫遷移腳本 (Alembic)

### 模型推論
- [ ] 模型載入器實作 (單例模式，避免重複載入)
- [ ] DQN/XGBoost 推論邏輯實作
- [ ] 預測結果儲存至資料庫

### 快取機制
- [ ] Redis 快取整合
- [ ] 客戶預測結果快取 (TTL: 24 小時)
- [ ] 快取鍵格式: `predict:{customer_id}:{model_version}`

### API 文件與測試
- [ ] Swagger UI 自動生成 (FastAPI 內建)
- [ ] API 文件完整性 100%
- [ ] 單元測試覆蓋率 ≥ 80% (pytest)
- [ ] API 效能測試 (Locust / JMeter)

### 安全性
- [ ] JWT 認證機制實作
- [ ] API Key 認證 (選用)
- [ ] 速率限制 (rate limiting)
- [ ] CORS 配置

## Technical Details

### 專案結構
```
backend/
├── app/
│   ├── api/
│   │   └── v1/
│   │       ├── __init__.py
│   │       ├── predict.py      # 預測端點
│   │       ├── segment.py      # 分群端點
│   │       ├── models.py       # 模型管理端點
│   ├── core/
│   │   ├── config.py           # 配置管理
│   │   ├── security.py         # JWT 認證
│   ├── models/
│   │   ├── dqn_inference.py    # DQN 推論
│   │   ├── xgboost_inference.py # XGBoost 推論
│   │   ├── loader.py           # 模型載入器
│   ├── schemas/
│   │   ├── prediction.py       # Pydantic 模型
│   │   ├── segment.py
│   ├── db/
│   │   ├── models.py           # SQLAlchemy ORM
│   │   ├── crud.py             # 資料庫操作
│   │   ├── session.py          # DB Session
│   ├── utils/
│   │   ├── cache.py            # Redis 快取
│   │   ├── background.py       # 背景任務
│   ├── main.py                 # FastAPI 應用入口
├── tests/
│   ├── test_predict.py
│   ├── test_segment.py
├── alembic/                    # 資料庫遷移
├── requirements.txt
├── Dockerfile
└── docker-compose.yml
```

### 關鍵實作

#### 1. 模型載入器 (單例模式)
```python
# app/models/loader.py
import tensorflow as tf
import pickle

class ModelLoader:
    _instance = None
    _dqn_model = None
    _xgb_model = None
    _xgb_segment = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def get_dqn_model(self):
        if self._dqn_model is None:
            self._dqn_model = tf.keras.models.load_model('models/dqn_model.h5')
        return self._dqn_model

    def get_xgb_segment(self):
        if self._xgb_segment is None:
            with open('models/xgb_segment.pkl', 'rb') as f:
                self._xgb_segment = pickle.load(f)
        return self._xgb_segment
```

#### 2. 單筆預測端點
```python
# app/api/v1/predict.py
from fastapi import APIRouter, Depends
from app.models.loader import ModelLoader
from app.schemas.prediction import PredictionRequest, PredictionResponse
from app.utils.cache import get_redis_client
import numpy as np

router = APIRouter()

@router.post("/single", response_model=PredictionResponse)
async def predict_single(
    request: PredictionRequest,
    redis=Depends(get_redis_client)
):
    # 檢查快取
    cache_key = f"predict:{request.customer_id}:{MODEL_VERSION}"
    cached_result = redis.get(cache_key)
    if cached_result:
        return PredictionResponse.parse_raw(cached_result)

    # 模型推論
    model_loader = ModelLoader()
    model = model_loader.get_dqn_model()

    features = np.array(request.features).reshape(1, -1)
    predictions = model.predict(features)[0]

    # Top 3 推薦產品
    top_3_indices = np.argsort(predictions)[-3:][::-1]
    top_3_probs = predictions[top_3_indices]

    result = PredictionResponse(
        customer_id=request.customer_id,
        recommendations=[
            {"product_id": PRODUCT_NAMES[i], "probability": float(top_3_probs[j])}
            for j, i in enumerate(top_3_indices)
        ]
    )

    # 儲存至快取 (24 小時)
    redis.setex(cache_key, 86400, result.json())

    # 儲存至資料庫
    save_prediction_to_db(request.customer_id, result)

    return result
```

#### 3. 批量預測 (非同步)
```python
# app/api/v1/predict.py
from fastapi import BackgroundTasks
import uuid

@router.post("/batch")
async def predict_batch(
    file: UploadFile,
    background_tasks: BackgroundTasks
):
    task_id = str(uuid.uuid4())

    # 儲存上傳檔案
    file_path = f"/tmp/{task_id}.csv"
    with open(file_path, "wb") as f:
        f.write(await file.read())

    # 背景任務處理
    background_tasks.add_task(process_batch_prediction, task_id, file_path)

    return {"task_id": task_id, "status": "processing"}

def process_batch_prediction(task_id: str, file_path: str):
    # 載入 CSV
    df = pd.read_csv(file_path)

    # 批量推論
    model_loader = ModelLoader()
    model = model_loader.get_dqn_model()

    predictions = model.predict(df.values)

    # 儲存結果至資料庫
    for i, row in df.iterrows():
        save_prediction_to_db(row['customer_id'], predictions[i])

    # 更新任務狀態
    update_task_status(task_id, "completed")
```

#### 4. 資料庫模型 (SQLAlchemy)
```python
# app/db/models.py
from sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey, JSON
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class Customer(Base):
    __tablename__ = "customers"

    id = Column(Integer, primary_key=True, index=True)
    customer_id = Column(String(50), unique=True, nullable=False, index=True)
    features = Column(JSON, nullable=False)  # 86 維特徵向量
    created_at = Column(DateTime, default=datetime.utcnow)

class Prediction(Base):
    __tablename__ = "predictions"

    id = Column(Integer, primary_key=True, index=True)
    customer_id = Column(String(50), ForeignKey("customers.customer_id"), nullable=False)
    predicted_product = Column(String(50))
    probability = Column(Float)
    model_version = Column(String(20))
    predicted_at = Column(DateTime, default=datetime.utcnow)
```

#### 5. Redis 快取
```python
# app/utils/cache.py
import redis
from app.core.config import settings

def get_redis_client():
    return redis.Redis(
        host=settings.REDIS_HOST,
        port=settings.REDIS_PORT,
        db=0,
        decode_responses=True
    )
```

### 檔案位置
- **後端程式碼**: `backend/app/`
- **測試**: `backend/tests/`
- **Dockerfile**: `backend/Dockerfile`
- **需求檔**: `backend/requirements.txt`

### 效能目標
- 單筆預測回應時間: < 3 秒 (95th percentile)
- 批量預測 (500 筆): < 10 分鐘
- 同時支援 50 並發請求
- API 可用性: ≥ 99%

## Dependencies

### 外部依賴
- [ ] Task 002 完成 (訓練好的模型檔案)
- [ ] Python 環境已安裝相關套件：
  - FastAPI >= 0.95.0
  - uvicorn >= 0.20.0
  - SQLAlchemy >= 1.4.0
  - alembic >= 1.9.0
  - redis >= 4.5.0
  - python-jose[cryptography] (JWT)
  - python-multipart (檔案上傳)
  - pytest >= 7.2.0
  - httpx >= 0.23.0 (測試用)

### 內部依賴
- [ ] PostgreSQL 資料庫已啟動
- [ ] Redis 已啟動
- [ ] 模型檔案已放置於 `models/` 目錄

## Effort Estimate

- **規模**: M (中型)
- **預估時數**: 60 小時 (3 週，每週 20 小時)
  - API 端點開發: 20 小時
  - 資料庫整合: 12 小時
  - 模型推論邏輯: 12 小時
  - 快取與效能優化: 8 小時
  - 單元測試: 8 小時
- **可並行**: false (依賴 Task 002 完成)

## Definition of Done

- [x] 所有 API 端點實作完成並通過測試
- [x] Swagger UI 可存取，API 文件完整
- [x] 單元測試覆蓋率 ≥ 80%
- [x] API 效能測試通過 (50 並發，回應時間 < 3 秒)
- [x] PostgreSQL 與 Redis 整合完成
- [x] 模型推論邏輯正確，結果可儲存至資料庫
- [x] JWT 認證機制運作正常
- [x] Code Review 完成
- [x] Dockerfile 與 docker-compose.yml 已建立
